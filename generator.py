"""
æ•°æ®é›†ç”Ÿæˆå™¨æ ¸å¿ƒå®ç°
å°è£…æ‰€æœ‰å¤æ‚çš„ç”Ÿæˆé€»è¾‘ï¼Œæä¾›ç®€æ´çš„å¯¹å¤–æ¥å£
"""

import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Callable
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
import time
import random
from collections import Counter

from openai_client import create_azure_openai_client
from person_profile import ProfileGenerator, PersonaProfile, ScenarioProfile


# ==================== é…ç½®ç±» ====================

@dataclass
class GenerationConfig:
    """ç”Ÿæˆé…ç½®"""
    # å¿…éœ€å‚æ•°
    api_key: str
    endpoint: str
    
    # LLMé…ç½®
    engine: str = "gpt-4.1"
    model: str = "gpt-4.1"
    temperature: float = 0.7
    api_version: str = "2025-03-01-preview"
    
    # ç”Ÿæˆé…ç½®
    batch_size: int = 10
    max_retries: int = 3
    retry_delay: float = 1.0
    timeout: float = 30.0
    
    # äººç‰©ç”»åƒé…ç½® - æ”¯æŒå¤šç§ç”»åƒéšæœºé€‰æ‹©
    persona_presets: List[str] = field(default_factory=lambda: [
        "basic_chinese_customer", 
        "business_customer", 
        "tech_support_user"
    ])
    scenario_types: List[str] = field(default_factory=lambda: ["å®¢æœå’¨è¯¢", "é”€å”®æ²Ÿé€š", "æŠ€æœ¯æ”¯æŒ", "è´·æ¬¾å’¨è¯¢", "è´·æ¬¾ä¿¡æ¯æ ¸å®"])
    
    # è¾“å‡ºé…ç½®
    output_dir: str = "./output"
    output_format: str = "jsonl"  # json, jsonl
    include_metadata: bool = True
    
    # æ—¥å¿—é…ç½®
    log_level: str = "INFO"


# ==================== æ ¸å¿ƒç”Ÿæˆå™¨ ====================

class ConversationGenerator:
    """å¯¹è¯ç”Ÿæˆå™¨ - æ ¸å¿ƒå®ç°ç±»"""
    
    def __init__(self, config: GenerationConfig):
        self.config = config
        self.profile_generator = ProfileGenerator()
        self.llm = self._create_llm_client()
        self._setup_logging()
    
    def _create_llm_client(self):
        """åˆ›å»ºLLMå®¢æˆ·ç«¯"""
        return create_azure_openai_client(
            api_key=self.config.api_key,
            endpoint=self.config.endpoint,
            engine=self.config.engine,
            model=self.config.model,
            temperature=self.config.temperature,
            api_version=self.config.api_version
        )
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=getattr(logging, self.config.log_level),
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    async def generate_single_conversation(self, persona: PersonaProfile = None, scenario: ScenarioProfile = None) -> Dict[str, Any]:
        """ç”Ÿæˆå•æ¡å¯¹è¯"""
        # å¦‚æœæ²¡æœ‰æä¾›ç”»åƒï¼Œåˆ™éšæœºé€‰æ‹©ä¸€ç§ç”»åƒç±»å‹ç”Ÿæˆ
        if not persona:
            # ğŸ”¥ ä»å¤šç§ç”»åƒä¸­éšæœºé€‰æ‹©
            persona_preset = random.choice(self.config.persona_presets)
            persona = self.profile_generator.generate_persona(persona_preset)
            self.logger.debug(f"ğŸ­ éšæœºé€‰æ‹©ç”»åƒç±»å‹: {persona_preset}")
        
        if not scenario:
            scenario_type = random.choice(self.config.scenario_types)
            scenario = self.profile_generator.generate_scenario(scenario_type)
        
        # åˆ›å»ºæç¤ºè¯
        prompt = self.profile_generator.create_conversation_prompt(persona, scenario)
        
        # è°ƒç”¨LLMç”Ÿæˆ
        start_time = time.time()
        try:
            response = await asyncio.wait_for(
                asyncio.to_thread(self.llm.complete, prompt),
                timeout=self.config.timeout
            )
            generation_time = time.time() - start_time
            
            # è§£æå¯¹è¯
            conversation = self._parse_response(str(response))
            
            # æ„å»ºç»“æœ
            result = {
                "conversation": conversation,
                "persona": persona.to_dict(),
                "scenario": scenario.to_dict()
            }
            
            # æ·»åŠ å…ƒæ•°æ®
            if self.config.include_metadata:
                result["metadata"] = {
                    "generated_at": datetime.now().isoformat(),
                    "generation_time": generation_time,
                    "model": self.config.model,
                    "temperature": self.config.temperature,
                    "persona_preset": getattr(persona, 'preset_name', 'unknown'),  # ğŸ”¥ è®°å½•ç”»åƒç±»å‹
                    "scenario_type": scenario.scenario_type
                }
            
            self.logger.info(f"âœ… å¯¹è¯ç”ŸæˆæˆåŠŸï¼Œè€—æ—¶ {generation_time:.2f}s")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¹è¯ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise
    
    def _parse_response(self, response_text: str) -> List[Dict[str, str]]:
        """è§£æLLMå“åº”ä¸ºå¯¹è¯æ ¼å¼"""
        try:
            # æå–JSONéƒ¨åˆ†
            if "```json" in response_text:
                json_part = response_text.split("```json")[1].split("```")[0].strip()
            elif "{" in response_text and "}" in response_text:
                start_idx = response_text.find("{")
                end_idx = response_text.rfind("}") + 1
                json_part = response_text[start_idx:end_idx]
            else:
                json_part = response_text.strip()
            
            parsed = json.loads(json_part)
            
            # ç¡®ä¿è¿”å›å¯¹è¯æ ¼å¼
            if "conversation" in parsed:
                return parsed["conversation"]
            elif isinstance(parsed, list):
                return parsed
            else:
                return [{"role": "assistant", "content": str(parsed)}]
                
        except json.JSONDecodeError:
            self.logger.warning(f"JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
            return [{"role": "assistant", "content": response_text}]
    
    async def generate_batch_conversations(self, count: int) -> List[Dict[str, Any]]:
        """æ‰¹é‡ç”Ÿæˆå¯¹è¯"""
        self.logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {count} æ¡å¯¹è¯")
        
        results = []
        
        for i in range(count):
            try:
                # å¸¦é‡è¯•çš„ç”Ÿæˆ
                result = await self._generate_with_retry()
                if result:
                    results.append(result)
                    self.logger.info(f"ğŸ“ˆ è¿›åº¦: {len(results)}/{count}")
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                if i < count - 1:
                    await asyncio.sleep(self.config.retry_delay)
                    
            except Exception as e:
                self.logger.error(f"ç¬¬ {i+1} æ¡ç”Ÿæˆå¤±è´¥: {str(e)}")
                continue
        
        self.logger.info(f"âœ¨ æ‰¹é‡ç”Ÿæˆå®Œæˆ: {len(results)}/{count} æˆåŠŸ")
        return results
    
    async def _generate_with_retry(self) -> Optional[Dict[str, Any]]:
        """å¸¦é‡è¯•çš„å•æ¡ç”Ÿæˆ"""
        for attempt in range(self.config.max_retries):
            try:
                return await self.generate_single_conversation()
            except Exception as e:
                self.logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {str(e)}")
                if attempt < self.config.max_retries - 1:
                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))
                else:
                    self.logger.error(f"é‡è¯• {self.config.max_retries} æ¬¡åä»å¤±è´¥")
        return None
    
    async def save_conversations(self, conversations: List[Dict[str, Any]], filename: str = None) -> str:
        """ä¿å­˜å¯¹è¯æ•°æ®"""
        # ç”Ÿæˆæ–‡ä»¶å
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dataset_{timestamp}.{self.config.output_format}"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(self.config.output_dir) / filename
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ ¹æ®æ ¼å¼ä¿å­˜
        if self.config.output_format == "jsonl":
            with open(output_path, 'w', encoding='utf-8') as f:
                for conv in conversations:
                    f.write(json.dumps(conv, ensure_ascii=False) + '\n')
        else:  # json
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(conversations, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        await self._generate_report(conversations, output_path)
        
        self.logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)
    
    async def _generate_report(self, conversations: List[Dict[str, Any]], output_path: Path):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = self._calculate_stats(conversations)
        
        report = {
            "summary": {
                "total_conversations": len(conversations),
                "generated_at": datetime.now().isoformat(),
                "config": {
                    "model": self.config.model,
                    "temperature": self.config.temperature,
                    "persona_presets": self.config.persona_presets,  # ğŸ”¥ ä½¿ç”¨æ–°çš„å­—æ®µå
                    "scenario_types": self.config.scenario_types
                }
            },
            "statistics": stats
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = output_path.with_suffix('.report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
    
    def _calculate_stats(self, conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if not conversations:
            return {}
        
        conversation_lengths = []
        occupations = []
        scenarios = []
        persona_presets = []  # ğŸ”¥ æ–°å¢ï¼šç”»åƒç±»å‹ç»Ÿè®¡
        
        for conv in conversations:
            # å¯¹è¯é•¿åº¦ç»Ÿè®¡
            if "conversation" in conv:
                conversation_lengths.append(len(conv["conversation"]))
            
            # èŒä¸šç»Ÿè®¡
            if "persona" in conv and "profile" in conv["persona"]:
                occupation = conv["persona"]["profile"].get("èŒä¸š")
                if occupation:
                    occupations.append(occupation)
            
            # åœºæ™¯ç»Ÿè®¡
            if "scenario" in conv:
                scenario_type = conv["scenario"].get("scenario_type")
                if scenario_type:
                    scenarios.append(scenario_type)
            
            # ğŸ”¥ ç”»åƒç±»å‹ç»Ÿè®¡
            if "metadata" in conv and "persona_preset" in conv["metadata"]:
                persona_preset = conv["metadata"]["persona_preset"]
                if persona_preset:
                    persona_presets.append(persona_preset)
        
        return {
            "conversation_length": {
                "average": sum(conversation_lengths) / len(conversation_lengths) if conversation_lengths else 0,
                "min": min(conversation_lengths) if conversation_lengths else 0,
                "max": max(conversation_lengths) if conversation_lengths else 0
            },
            "occupation_distribution": dict(Counter(occupations)),
            "scenario_distribution": dict(Counter(scenarios)),
            "persona_preset_distribution": dict(Counter(persona_presets))  # ğŸ”¥ æ–°å¢ç»Ÿè®¡
        }


# ==================== å¯¹å¤–æ¥å£ ====================

class DatasetExpander:
    """æ•°æ®é›†æ‰©å±•å™¨ - å¯¹å¤–æ¥å£ç±»"""
    
    def __init__(self, api_key: str, endpoint: str, **kwargs):
        """åˆå§‹åŒ–æ‰©å±•å™¨"""
        # ğŸ”¥ å‘åå…¼å®¹ï¼šå¤„ç†æ—§çš„ persona_preset å‚æ•°
        if 'persona_preset' in kwargs and 'persona_presets' not in kwargs:
            # å¦‚æœåªæä¾›äº†æ—§çš„ persona_presetï¼Œè½¬æ¢ä¸ºæ–°çš„ persona_presets
            kwargs['persona_presets'] = [kwargs['persona_preset']]
            del kwargs['persona_preset']  # ç§»é™¤æ—§å‚æ•°
        
        self.config = GenerationConfig(
            api_key=api_key,
            endpoint=endpoint,
            **kwargs
        )
        self.generator = ConversationGenerator(self.config)
    
    async def expand(self, count: int, output_filename: str = None) -> str:
        """æ‰©å±•æ•°æ®é›† - ä¸»è¦å¯¹å¤–æ¥å£"""
        # æ‰¹é‡ç”Ÿæˆå¯¹è¯
        conversations = await self.generator.generate_batch_conversations(count)
        
        # ä¿å­˜ç»“æœ
        output_path = await self.generator.save_conversations(conversations, output_filename)
        
        return output_path
    
    async def generate_single(self) -> Dict[str, Any]:
        """ç”Ÿæˆå•æ¡å¯¹è¯"""
        return await self.generator.generate_single_conversation()
    
    def update_config(self, **kwargs):
        """æ›´æ–°é…ç½®"""
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)


# ==================== ä¾¿æ·å‡½æ•° ====================

async def expand_dataset(
    count: int,
    api_key: str,
    endpoint: str,
    output_dir: str = "./output",
    output_filename: str = None,
    **kwargs
) -> str:
    """
    ä¾¿æ·çš„æ•°æ®é›†æ‰©å±•å‡½æ•°
    
    Args:
        count: ç”Ÿæˆå¯¹è¯æ•°é‡
        api_key: OpenAI API Key
        endpoint: OpenAI Endpoint
        output_dir: è¾“å‡ºç›®å½•
        output_filename: è¾“å‡ºæ–‡ä»¶å
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
    
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    expander = DatasetExpander(
        api_key=api_key,
        endpoint=endpoint,
        output_dir=output_dir,
        **kwargs
    )
    
    return await expander.expand(count, output_filename)


async def generate_single_conversation(
    api_key: str,
    endpoint: str,
    **kwargs
) -> Dict[str, Any]:
    """
    ç”Ÿæˆå•æ¡å¯¹è¯çš„ä¾¿æ·å‡½æ•°
    """
    expander = DatasetExpander(
        api_key=api_key,
        endpoint=endpoint,
        **kwargs
    )
    
    return await expander.generate_single()


# ==================== é¢„è®¾é…ç½® ====================

class PresetConfigs:
    """é¢„è®¾é…ç½®ç±»"""
    
    @staticmethod
    def customer_service(api_key: str, endpoint: str) -> DatasetExpander:
        """å®¢æœå¯¹è¯é…ç½® - ä½¿ç”¨å¤šç§å®¢æˆ·ç”»åƒ"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=["basic_chinese_customer", "business_customer"],  # ğŸ”¥ å¤šç§ç”»åƒ
            scenario_types=["å®¢æœå’¨è¯¢"],
            temperature=0.7,
            output_format="jsonl"
        )
    
    @staticmethod
    def sales_conversation(api_key: str, endpoint: str) -> DatasetExpander:
        """é”€å”®å¯¹è¯é…ç½® - ä¸“æ³¨å•†ä¸šå®¢æˆ·"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=["business_customer"],  # ğŸ”¥ é€‚åˆé”€å”®çš„ç”»åƒ
            scenario_types=["é”€å”®æ²Ÿé€š"],
            temperature=0.8,
            output_format="json"
        )
    
    @staticmethod
    def tech_support(api_key: str, endpoint: str) -> DatasetExpander:
        """æŠ€æœ¯æ”¯æŒé…ç½® - å¤šç§ç”¨æˆ·ç±»å‹"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=["tech_support_user", "basic_chinese_customer"],  # ğŸ”¥ æŠ€æœ¯ç”¨æˆ·å’Œæ™®é€šç”¨æˆ·
            scenario_types=["æŠ€æœ¯æ”¯æŒ"],
            temperature=0.6,
            output_format="jsonl"
        )
    
    @staticmethod
    def loan_consultation(api_key: str, endpoint: str) -> DatasetExpander:
        """è´·æ¬¾å’¨è¯¢é…ç½® - å•†ä¸šå’Œæ™®é€šå®¢æˆ·"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=["business_customer", "basic_chinese_customer"],  # ğŸ”¥ å¤šç§å®¢æˆ·ç±»å‹
            scenario_types=["è´·æ¬¾å’¨è¯¢"],
            temperature=0.7,
            output_format="jsonl"
        )
    
    @staticmethod
    def loan_verification(api_key: str, endpoint: str) -> DatasetExpander:
        """è´·æ¬¾ä¿¡æ¯æ ¸å®é…ç½® - å•†ä¸šå’Œæ™®é€šå®¢æˆ·"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=["business_customer", "basic_chinese_customer"],  # ğŸ”¥ å¤šç§å®¢æˆ·ç±»å‹
            scenario_types=["è´·æ¬¾ä¿¡æ¯æ ¸å®"],
            temperature=0.6,
            output_format="jsonl"
        )
    
    @staticmethod
    def comprehensive_service(api_key: str, endpoint: str) -> DatasetExpander:
        """ç»¼åˆæœåŠ¡é…ç½® - å¹³è¡¡çš„ç”»åƒåˆ†å¸ƒ"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=[  # ğŸ”¥ ç²¾é€‰çš„ç”»åƒç»„åˆ
                "basic_chinese_customer",
                "business_customer",
                "tech_support_user"
            ],
            scenario_types=["å®¢æœå’¨è¯¢", "é”€å”®æ²Ÿé€š", "æŠ€æœ¯æ”¯æŒ", "è´·æ¬¾å’¨è¯¢", "è´·æ¬¾ä¿¡æ¯æ ¸å®"],
            temperature=0.7,
            output_format="jsonl"
        )
    
    @staticmethod
    def diverse_scenarios(api_key: str, endpoint: str) -> DatasetExpander:
        """å¤šæ ·åŒ–åœºæ™¯é…ç½® - æ‰€æœ‰ç”»åƒç±»å‹"""
        return DatasetExpander(
            api_key=api_key,
            endpoint=endpoint,
            persona_presets=[  # ğŸ”¥ ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ç”»åƒç±»å‹
                "basic_chinese_customer",
                "business_customer", 
                "tech_support_user",
                "international_user",  # å¦‚æœä½ æœ‰è¿™ä¸ªç”»åƒçš„è¯
                "diverse_conditional_customer"  # åŒ…å«æ¡ä»¶è½´çš„å¤æ‚ç”»åƒ
            ],
            scenario_types=["å®¢æœå’¨è¯¢", "é”€å”®æ²Ÿé€š", "æŠ€æœ¯æ”¯æŒ", "è´·æ¬¾å’¨è¯¢", "è´·æ¬¾ä¿¡æ¯æ ¸å®"],
            temperature=0.7,
            output_format="jsonl"
        )